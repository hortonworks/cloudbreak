{%- from 'fluent/settings.sls' import fluent with context %}
{%- from 'databus/settings.sls' import databus with context %}
{%- if databus.valid and fluent.dbusMonitoringEnabled %}
<worker {{ fluent.monitoringWorkerIndex }}>
<source>
  @type tail
  format none
  path ["/var/log/metrics-collector/health_checks.json", "/var/log/metrics-collector/metrics.json"]
  pos_file /var/log/metrics-collector/metrics-collector.pos
  tag metrics.metrics-jsons
  read_from_head true
</source>

<match metrics.*>
  @type copy
  <store ignore_error>
    @type                            databus
    credential_file                  /etc/{{ fluent.binary }}/databus_credential
    credential_profile_name          dbus
    credential_file_reload_interval  60
    debug                            false
    endpoint                         "{{ databus.endpoint }}"
    event_message_field              message
    headers                          {{ fluent.dbusMonitoringAppHeaders }}
    stream_name                      {{ fluent.dbusMonitoringStreamName }}
    partition_key                    "#{Socket.gethostname}"{%- if fluent.proxyUrl %}
    proxy_url                        "{{ fluent.proxyUrl }}"{%- if fluent.proxyAuth %}
    proxy_username                   "{{ fluent.proxyUser }}"
    proxy_password                   "{{ fluent.proxyPassword }}"{% endif %}{% if fluent.noProxyHosts and fluent.fluentVersion > 3 %}
    no_proxy                         "{{ fluent.noProxyHosts }}"{% endif %}{% endif %}{% if fluent.environmentRegion %}
    region                           "{{ fluent.environmentRegion }}"{% endif %}
    <buffer tag,time>
      @type file
      path /var/log/{{ fluent.binary }}/monitoring_databus
      timekey 1m
      timekey_wait 0s
      chunk_limit_size 600k
      flush_at_shutdown true
      retry_max_interval 1200
    </buffer>
  </store>
</match>
</worker>
{% elif fluent.dbusMonitoringEnabled %}
# DBUS settings are not valid - check dbus credentials file
{% else %}
# DBUS monitoring is disabled
{% endif %}