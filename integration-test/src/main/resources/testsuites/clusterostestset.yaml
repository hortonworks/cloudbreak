name: "AWS cluster tests on different oses"
parallel: tests
threadCount: 4
parameters:
  awsRegion: eu-central-1
  awsAvailabilityZone: eu-central-1a
  awsCredentialName: autotesting-clusters-aws
tests:
#
#  - name: "aws base image datascience on sles12"
#    preserveOrder: true
#    parameters:
#      clusterName: aws-suse-datasci
#      provider: aws
#      blueprintName: "Data Science: Apache Spark 2, Apache Zeppelin"
#      imageos: sles12
#      instancegroupName: worker
#      awsInstanceType: m5.2xlarge
#    classes:
#      - name: com.sequenceiq.it.cloudbreak.ClusterTests
#        includedMethods:
#          - testCreateNewClusterWithOs
#          - testScaleCluster
#          - testStopCluster
#          - testStartCluster
#          - testTerminateCluster
#
# !!!!! I (PERDOS) REMOVED THIS TEST, BUT ERROR WAS:
#Repository 'SLES12-SP3-Updates' is up to date.
#Retrieving repository 'Network Utilities (SLE_12_SP3)' metadata [..
#Abort, retry, ignore? [a/r/i/...? shows all options] (a): error]
#Repository 'nginx' is up to date.
#Stderr: Download (curl) error for 'http://download.opensuse.org/repositories/network:/utilities/SLE_12_SP3/repodata/3cf4a8cbe55cf3ec19557e90aacb6ddcf1d77de39548abc5a34051db5e50c76a-primary.xml.gz':
#Error code: Connection failed
#Error message: Failed to connect to mirror.tspu.ru port 80: Connection refused
#
#Cannot read input: bad stream or EOF.
#If you run zypper without a terminal, use '--non-interactive' global
#option to make zypper use default answers to prompts.
#Repository 'Network Utilities (SLE_12_SP3)' is invalid.
#[network_utilities|http://download.opensuse.org/repositories/network:/utilities/SLE_12_SP3/] Valid metadata not found at specified URL
#Please check if the URIs defined for this repository are pointing to a valid repository.
#Skipping repository 'Network Utilities (SLE_12_SP3)' because of the above error.
#Some of the repositories have not been refreshed because of an error. |
#Name: ambari-agent
#Comment: Running scope as unit run-reeefd4fb56894f0b87d0e098a00191bb.scope.
#Job for ambari-agent.service failed because the control process exited with error code. See "systemctl status ambari-agent.service" and "journalctl -xe" for details. |
#Name: /etc/ambari-agent/conf/public_hostname.sh
#Comment: Parent directory not present |
#Name: /etc/ambari-agent/conf/ambari-agent.ini
#Comment: /etc/ambari-agent/conf/ambari-agent.ini: file not found |
#Name: /etc/ambari-agent/conf/internal_hostname.sh
#Comment: Parent directory not present |
#Name: /etc/ambari-agent/conf/ambari-agent.ini
#Comment: /etc/ambari-agent/conf/ambari-agent.ini: file not found |
#Name: /etc/ambari-agent/conf/ambari-agent.ini
#Comment: /etc/ambari-agent/conf/ambari-agent.ini: file not found |
#Comment: One or more requisite failed: ambari.repo.import_ambari_repo_key |
#Comment: One or more requisite failed: ambari.agent./etc/ambari-agent/conf/public_hostname.sh |
#Comment: One or more requisite failed: ambari.agent./etc/ambari-agent/conf/internal_hostname.sh
#
  - name: "aws base image datascience on redhat7"
    preserveOrder: true
    parameters:
      clusterName: aws-redhat7-datasci
      provider: aws
      blueprintName: "Data Science: Apache Spark 2, Apache Zeppelin"
      imageos: redhat7
      instancegroupName: worker
      awsInstanceType: m5.2xlarge
    classes:
      - name: com.sequenceiq.it.cloudbreak.ClusterTests
        includedMethods:
          - testCreateNewClusterWithOs
          - testScaleCluster
          - testStopCluster
          - testStartCluster
          - testTerminateCluster
  - name: "aws base image edw analytics on ubuntu"
    preserveOrder: true
    parameters:
      clusterName: aws-ubuntu-datasci
      provider: aws
      blueprintName: "Data Science: Apache Spark 2, Apache Zeppelin"
      imageos: ubuntu16
      instancegroupName: worker
      awsInstanceType: m5.2xlarge
    classes:
      - name: com.sequenceiq.it.cloudbreak.ClusterTests
        includedMethods:
          - testCreateNewClusterWithOs
          - testScaleCluster
          - testStopCluster
          - testStartCluster
          - testTerminateCluster
