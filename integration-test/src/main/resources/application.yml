spring:
    freemarker:
        checkTemplateLocation: false

# The logfiles will be created in this directory, LOG_PATH system property will be set and can be used in logback.xml
# http://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-logging.html#boot-features-logging-file-output
logging:
    path: ${integrationtest.outputdir}

mock:
  server:
    address: localhost
  image:
    catalog:
      url: https://localhost:9443/imagecatalog

integrationtest:
  threadCount: 8
  parallel: methods
  timeOut: 6000000
  spark:
    sparkPoolSize: 12
  command: suiteurls
  outputdir: .
  publicKeyFile:
  database:
    connectionUrl: jdbc:postgresql://localhost:5432/
    username: postgres
    password: postgres
  cloudbreak:
    server: http://localhost
  periscope:
    server: http://localhost
  freeipa:
    server: http://localhost
  environment:
    server: http://localhost
  sdx:
    server: http://localhost
  redbeams:
    server: http://localhost
  user:
    accesskey: Y3JuOmFsdHVzOmlhbTp1cy13ZXN0LTE6Y2xvdWRlcmE6dXNlcjptb2NrdXNlcg==
    secretkey: nHkdxgZR0BaNHaSYM3ooS6rIlpV5E+k1CIkr+jFId2g=
  testsuite:
    pollingInterval: 1000
    threadPoolSize: 8
    skipRemainingTestsAfterOneFailed: true
    cleanUpOnFailure: false
  sshPublicKey: "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC0Rfl2G2vDs6yc19RxCqReunFgpYj+ucyLobpTCBtfDwzIbJot2Fmife6M42mBtiTmAK6x8kcUEeab6CB4MUzsqF7vGTFUjwWirG/XU5pYXFUBhi8xzey+KS9KVrQ+UuKJh/AN9iSQeMV+rgT1yF5+etVH+bK1/37QCKp3+mCqjFzPyQOrvkGZv4sYyRwX7BKBLleQmIVWpofpjT7BfcCxH877RzC5YMIi65aBc82Dl6tH6OEiP7mzByU52yvH6JFuwZ/9fWj1vXCWJzxx2w0F1OU8Zwg8gNNzL+SVb9+xfBE7xBHMpYFg72hBWPh862Ce36F4NZd3MpWMSjMmpDPh"
  defaultPrivateKeyFile:
  subnetCidr: 10.0.0.0/16
  accessCidr: 0.0.0.0/0
  imageCatalogName: cloudbreak-default
  imageCatalogUrl: https://cloudbreak-imagecatalog.s3.amazonaws.com/v3-dev-cb-image-catalog.json
  gatewayPort: null
  imageValidation:
    sourceCatalogName: v3-dev
    sourceCatalogUrl: https://cloudbreak-imagecatalog.s3.amazonaws.com/v3-dev-cb-image-catalog.json
  tags:
    auto: tesztelek
  clusterShape: LIGHT_DUTY
  internalClusterShape: CUSTOM
  internalSdxBlueprintName: "%s - SDX Light Duty: Apache Hive Metastore, Apache Ranger, Apache Atlas"
  internalDistroXBlueprintName: "%s - Data Engineering: Apache Spark, Apache Hive, Apache Oozie"
  clouderamanager:
    defaultUser: admin
    defaultPassword: Admin123
    defaultPort: 7180
  cloudProvider: MOCK
  runtimeVersion: 7.2.0

  spot:
    enabledCloudPlatforms:
      - AWS

  # aws parameters
  aws:
    region: eu-central-1
    location: eu-central-1
    availabilityZone: eu-central-1a
    vpcId: vpc-0fc0a422f82ea8eec
    subnetIds:
      - subnet-025e39ebeb6efeca8
      - subnet-0d8756068a4e78bd1
      - subnet-065019e58cbefd9b8
    publicKeyId: api-e2e-test
    credential:
      type: role
      roleArn: 
      accessKeyId:
      secretKey:
    instance:
      type: m5.2xlarge
      volumeSize: 100
      volumeCount: 1
      volumeType: gp2
    baseimage:
      imageId:
    dynamoTableName: apitesting
    cloudstorage:
      s3:
        instanceProfile:
      baseLocation:
      fileSystemType: S3
    hybridCloudSecurityGroupID: sg-0c73a7f815c452e9d

  # azure parameters
  azure:
    availabilityZone:
    region: West US
    location: West US
    network:
      networkId: CDP-Build-US-W
      noPublicIp: false
      resourceGroupName: CDP-Build
      subnetIds:
        - default
        - GatewaySubnet
    credential:
      appId:
      appPassword:
      subscriptionId:
      tenantId:
    instance:
      type: Standard_D16_v3
      volumeSize: 100
      volumeCount: 1
      volumeType: StandardSSD_LRS
    baseimage:
      imageId:
    cloudstorage:
      accountKey:
      accountName:
      baseLocation:
      fileSystemType: ADLS_GEN_2
      adlsGen2:
        assumerIdentity:
        loggerIdentity:
      secure: false

  # gcp parameters
  gcp:
    availabilityZone: europe-west2-a
    region: europe-west2
    location: europe-west2
    vpcId:
    subnetId:
    credential:
      type: json
      json:
      p12:
      serviceAccountId:
      projectId:
    instance:
      type: n1-standard-8
      volumeSize: 100
      volumeCount: 1
      volumeType: pd-standard

  # openstack parameters
  openstack:
    availabilityZone: nova
    region: RegionOne
    location: Texas
    publicNetId: 999e09bc-cf75-4a19-98fb-c0b4ddee6d93
    networkingOption: self-service
    instance:
      type: m1.xlarge
      volumeSize: 100
      volumeCount: 0
      volumeType: HDD
    credential:
      endpoint:
      tenant:
      userName:
      password:

  # yarn parameters
  yarn:
    defaultBlueprintName: "%s - SDX Light Duty: Apache Hive Metastore, Apache Ranger, Apache Atlas"
    availabilityZone:
    region: default
    location: Frankfurt
    credential:
      endpoint: http://yprod001.l42scl.hortonworks.com:9191
    instance:
      cpuCount: 4
      memory: 8192
      volumeSize: 0
      volumeCount: 0
    queue: infrastructure-services
    networkCidr: 172.27.0.0/16
    baseimage:
      imageId:

  # mock parameters
  mock:
    region: Europe
    location: London
    availabilityZone: London
    vpcId: vpc1
    subnetIds:
      - net1
      - net2
    publicKeyId: publicKeyId
    internetGateway: "1.1.1.1"
    credential:
      type: key
      roleArn:
      accessKeyId:
      secretKey:
    instance:
      type: m5.2xlarge
      volumeSize: 100
      volumeCount: 1
      volumeType: gp2
    baseimage:
      redhat7:
        imageId: ee68297d-59b3-4cb0-419a-f9e00763bdb4
        blueprints:
          - "%s - Data Engineering: Apache Spark, Apache Hive, Apache Oozie"
    cloudstorage:
      s3:
        instanceProfile:
      baseLocation:
      fileSystemType: S3

  cleanup:
      retryCount: 3
      cleanupBeforeStart: false

  defaultBlueprintName:

  kibana:
    url: https://logs-dev.sre.cloudera.com/app/kibana#/discover
    cluster:
    app:
